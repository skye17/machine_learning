{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.io import imread, imsave, imshow\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.shape\n",
    "train_target = train['label'].values\n",
    "train_data = train.drop('label', axis = 1).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_target, test_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skye17/ml/anaconda2/envs/dato-env/lib/python2.7/site-packages/skimage/io/_plugins/matplotlib_plugin.py:71: UserWarning: Non-standard image type; displaying image with stretched contrast.\n",
      "  warnings.warn(\"Non-standard image type; displaying image with \"\n",
      "/home/skye17/ml/anaconda2/envs/dato-env/lib/python2.7/site-packages/skimage/io/_plugins/matplotlib_plugin.py:74: UserWarning: Low image dynamic range; displaying image with stretched contrast.\n",
      "  warnings.warn(\"Low image dynamic range; displaying image with \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe6a65e9910>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAD8CAYAAAAfZJO2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAVmgzYRpaNXPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe6a74ba690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(train_data[0].reshape((28, 28)), 'matplotlib', cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1.0 + np.exp(-z))\n",
    "\n",
    "def one_hot(y):\n",
    "    vec = np.zeros(10)\n",
    "    vec[y] = 1\n",
    "    return vec.reshape((vec.size), 1)\n",
    "\n",
    "class Network(object):\n",
    "    \n",
    "    def __init__(self, sizes):\n",
    "        self.num_layers = len(sizes)\n",
    "        self.layers = [np.zeros(y) for y in sizes]\n",
    "        self.sizes = sizes\n",
    "        self.biases = np.array([np.random.randn(y, 1) for y in sizes[1:]])\n",
    "        #print self.biases.shape\n",
    "        self.weights = np.array([np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])])\n",
    "        #print self.weights.shape\n",
    "        \n",
    "    def feedforward(self, a):\n",
    "        \"\"\"Return the output of the network if \"a\" is input.\"\"\"\n",
    "        a_vec = a.reshape((a.size, 1))\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a_vec = sigmoid(np.dot(w,a_vec) + b)\n",
    "        return a_vec\n",
    "    \n",
    "    def feedforward_save(self, a):\n",
    "        a_vec = a.reshape((a.size, 1))\n",
    "        self.layers[0] = a_vec\n",
    "        i = 1\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a_vec = sigmoid(np.dot(w,a_vec) + b)\n",
    "            self.layers[i] = a_vec\n",
    "            i += 1\n",
    "        return a_vec\n",
    "        \n",
    "    def SGD(self, train_data, target,eta = 1.0, eps = 0.000001):\n",
    "        n, k = train_data.shape\n",
    "        Q = 0.0\n",
    "        diff = 1000\n",
    "        while abs(diff) > eps:\n",
    "            ind = np.random.choice(range(n), 1)\n",
    "            x = train_data[ind].reshape((k, 1))\n",
    "            y_vec = one_hot(target[ind])\n",
    "            # Прямой и обратный ход\n",
    "            out = self.feedforward_save(x)\n",
    "            Q_i = (np.linalg.norm(out - y_vec))**2\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(out-y_vec)\n",
    "            self.weights = [w-eta*nw\n",
    "                        for w, nw in zip(self.weights, delta_nabla_w)]\n",
    "            self.biases = [b-eta*nb\n",
    "                       for b, nb in zip(self.biases, delta_nabla_b)]\n",
    "            if Q == 0:\n",
    "                Q = Q_i\n",
    "            else:\n",
    "                diff = (Q_i - Q)/n\n",
    "                Q += diff\n",
    "         \n",
    "        \n",
    "    def backprop(self, out_errors):\n",
    "        delta_nabla_b = np.array([np.zeros(b.shape) for b in self.biases])\n",
    "        delta_nabla_w = np.array([np.zeros(w.shape) for w in self.weights])\n",
    "        errors = np.array([np.zeros(size) for size in self.sizes[1:]])\n",
    "        pred = self.layers[self.num_layers - 1]\n",
    "        errors[errors.size - 1] = out_errors\n",
    "        for i in xrange(errors.size - 1, -1, -1):\n",
    "            delta_nabla_b[i] = errors[i]*pred*(1-pred)\n",
    "            delta_nabla_w[i] = np.dot(pred*(1-pred)*errors[i],(self.layers[i]).T)\n",
    "            if i - 1 >= 0:\n",
    "                errors[i-1] = np.dot((self.weights[i]).T, pred*(1-pred)*errors[i])\n",
    "            pred = self.layers[i]\n",
    "        return delta_nabla_b, delta_nabla_w\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.SGD(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        print 'Predict'\n",
    "        return [np.argmax(self.feedforward(x)) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict\n",
      "0.0965178571429\n"
     ]
    }
   ],
   "source": [
    "nn = Network([784, 200,10])\n",
    "nn.fit(X_train, y_train)\n",
    "pred = nn.predict(X_test)\n",
    "accuracy = sum(pred == y_test)*1. / len(y_test)\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.947827380952\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators  = 100)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print accuracy_score(y_test, pred)\n",
    "#scores = cross_val_score(clf, train_data, train_target, cv = 3, scoring = 'accuracy', n_jobs = -1)\n",
    "#print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-7b36457114af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mg_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mg_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mg_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#scores = cross_val_score(g_clf, train_data, train_target, cv = 3, scoring = 'accuracy', n_jobs = -1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/skye17/ml/anaconda2/envs/dato-env/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    978\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[1;32m--> 980\u001b[1;33m                                     begin_at_stage, monitor)\n\u001b[0m\u001b[0;32m    981\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/skye17/ml/anaconda2/envs/dato-env/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[0;32m   1039\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplitter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m                                      random_state)\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/skye17/ml/anaconda2/envs/dato-env/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, y_pred, sample_weight, sample_mask, criterion, splitter, random_state)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[1;32m--> 766\u001b[1;33m                      check_input=False)\n\u001b[0m\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/skye17/ml/anaconda2/envs/dato-env/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    302\u001b[0m                                            max_leaf_nodes)\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "g_clf = GradientBoostingClassifier(n_estimators = 100, learning_rate = 1)\n",
    "g_clf.fit(X_train, y_train)\n",
    "g_pred = g_clf.predict(X_test)\n",
    "print accuracy_score(y_test, g_pred)\n",
    "#scores = cross_val_score(g_clf, train_data, train_target, cv = 3, scoring = 'accuracy', n_jobs = -1)\n",
    "#print np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm = SVC(kernel = 'linear', C = 0.1)\n",
    "svm.fit(X_train, y_train)\n",
    "s_pred = svm.predict(X_test)\n",
    "print accuracy_score(y_test, s_pred)\n",
    "\n",
    "#params = {'kernel':('linear', 'rbf'), 'C':np.power(10.0, np.arange(-1, 1))}\n",
    "#grid = GridSearchCV(svm, params, scoring = 'accuracy', n_jobs = -1, cv = 3)\n",
    "#grid.fit(X_train, y_train)\n",
    "#print grid.best_estimator_\n",
    "#print grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
